{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy.random as nprnd\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import lda\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "%matplotlib inline\n",
    "\n",
    "#Data Gathering and Preparation\n",
    "\n",
    "##Data prepocessing and Data integrity checks\n",
    "\n",
    "### Read data\n",
    "df = pd.read_csv(\"music.tsv\",delimiter='\\t',encoding='utf-8',header=None)\n",
    "### Rename the columns\n",
    "df.columns = ['userID','playerID','playerName','playNum']\n",
    "### Remove the missing values\n",
    "df.dropna(inplace=True)\n",
    "### Data cleaning and turned the complicated ID format to the simple one.\n",
    "_, user_id = np.unique(df.userID, return_inverse=True)\n",
    "_, player_id = np.unique(df.playerID, return_inverse=True)\n",
    "df['userID'] = user_id\n",
    "df['playerID'] = player_id\n",
    "df['userID'] = df['userID'].astype(np.int32)\n",
    "df['playerID'] = df['playerID'].astype(np.int32)\n",
    "df['playNum'] = df['playNum'].astype(np.int32)\n",
    "\n",
    "s_player = df[['playerID', 'playerName']].drop_duplicates(subset='playerID').set_index('playerID').sort_index()\n",
    "df.drop('playerName', axis=1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "print(df.userID.max())\n",
    "print(df.playerID.max())\n",
    "print(df.playNum.max())\n",
    "print(df.userID.min())\n",
    "print(df.playerID.min())\n",
    "print(df.playNum.min())\n",
    "\n",
    "## Using SQL\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "import sqlite3\n",
    "df.to_sql('data',engine)\n",
    "### connecting to the database \n",
    "connection = sqlite3.connect(\"data.db\")\n",
    "### Count the total play times of a user\n",
    "pd.read_sql_query('SELECT COUNT(*) FROM data GROUP BY userID', engine)\n",
    "### Count the total play times group by artist with a descent order\n",
    "pd.read_sql_query('SELECT playerID,COUNT(*) AS number FROM data GROUP BY playerID ORDER BY number DESC', engine)\n",
    "\n",
    "##Feature Engineering\n",
    "# pivot the matrix using sparse matrix. A low is a user, and each columns is the artist he listened, the values are the play times.\n",
    "user_item_sp_mat = coo_matrix((df.playNum, (df.userID, df.playerID)), (df.userID.max()+1, df.playerID.max()+1), dtype=np.int32)\n",
    "\n",
    "\n",
    "# Model (LDA)\n",
    "##This is a unsupervised Problem. We used Latent Dirichlet allocation(LDA) to do the dimensions reduction which is clustering.\n",
    "##We divided 160k artists into 20 class, according to the taste of users which is the latent variable.\n",
    "\n",
    "### Run LDA model\n",
    "lda = LatentDirichletAllocation(n_components=20, max_iter=10, random_state=0)\n",
    "lda.fit(user_item_sp_mat)\n",
    "\n",
    "### Check the comparable number of points in each cluster.\n",
    "for i in range(0,20):\n",
    "    print(lda.components_[[i]].size)\n",
    "### Check the covariance. In each cluster, in oder to check, we over it with 100000000\n",
    "for i in range(0,19):\n",
    "    print(np.cov(lda.components_[[i]])/100000000)\n",
    "\n",
    "## Interpretations for the clusters\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \", \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "print_top_words(lda, s_player.playerName, 5)\n",
    "\n",
    "## Investigate properties of those clusters\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lda, 'lda.pkl')\n",
    "lda.components_.shape\n",
    "user_components = lda.transform(user_item_sp_mat)\n",
    "user_components.shape\n",
    "\n",
    "## The process to use the model. Input is a artist's name and output is the artist(s) in the same style.\n",
    "def getName(name):\n",
    "    for i in range(s_player.shape[0]):\n",
    "        if s_player.iloc[i].playerName == name:\n",
    "            topic=lda.components_[:, i].argmax()\n",
    "            for j in range(0,9):\n",
    "                artists = lda.components_[[topic]].argsort(axis=1)\n",
    "                if s_player.iloc[artists[0][-j]].playerName == name:\n",
    "                    continue;\n",
    "                else:\n",
    "                    print(s_player.iloc[artists[0][-j]].playerName)\n",
    "## an example\n",
    "getName('bad religion')\n",
    "\n",
    "## clusters stable\n",
    "### Using samples because the original dataset is too large\n",
    "sample = df.iloc[0:100000]\n",
    "### pivot the matrix using sparse matrix. A low is a user, and each columns is the artist he listened, the values are the play times.\n",
    "user_item_sp_mat_1 = coo_matrix((sample.playNum, (sample.userID, sample.playerID)), (sample.userID.max()+1, sample.playerID.max()+1), dtype=np.int32)\n",
    "### Run LDA model time1\n",
    "lda_2 = LatentDirichletAllocation(n_components=20, max_iter=10)\n",
    "lda_2.fit(user_item_sp_mat_1)\n",
    "lda_2.transform(user_item_sp_mat_1)\n",
    "print_top_words(lda_2, s_player.playerName, 5)\n",
    "\n",
    "### Run LDA model time2\n",
    "lda_1 = LatentDirichletAllocation(n_components=20, max_iter=10)\n",
    "lda_1.fit(user_item_sp_mat_1)\n",
    "lda_1.transform(user_item_sp_mat_1)\n",
    "\n",
    "\n",
    "### Run LDA model time3\n",
    "lda_3 = LatentDirichletAllocation(n_components=20, max_iter=10)\n",
    "lda_3.fit(user_item_sp_mat_1)\n",
    "lda_3.transform(user_item_sp_mat_1)\n",
    "\n",
    "### Run LDA model time3\n",
    "lda_4 = LatentDirichletAllocation(n_components=20, max_iter=10)\n",
    "lda_4.fit(user_item_sp_mat_1)\n",
    "lda_4.transform(user_item_sp_mat_1)\n",
    "\n",
    "### Run LDA model time3\n",
    "lda_5 = LatentDirichletAllocation(n_components=20, max_iter=10)\n",
    "lda_5.fit(user_item_sp_mat_1)\n",
    "lda_5.transform(user_item_sp_mat_1)\n",
    "\n",
    "### choose topic number\n",
    "y11= np.sum(sum(np.cov(lda_11.transform(user_item_sp_mat_1))))\n",
    "y12=np.sum(sum(np.cov(lda_2.transform(user_item_sp_mat_1))))\n",
    "y13=np.sum(sum(np.cov(lda_12.transform(user_item_sp_mat_1))))\n",
    "y14=np.sum(sum(np.cov(lda_13.transform(user_item_sp_mat_1))))\n",
    "y1_sample = [y11,y12,y13,y14]\n",
    "x1_sample = [1,2,3,4]\n",
    "plt.plot(x1_sample,y1_sample)\n",
    "plt.show()\n",
    "\n",
    "###Plot the stability\n",
    "y1 = np.sum(sum(np.cov(lda_5.transform(user_item_sp_mat_1),lda_3.transform(user_item_sp_mat_1))))\n",
    "y2 = np.sum(sum(np.cov(lda_5.transform(user_item_sp_mat_1),lda_2.transform(user_item_sp_mat_1))))\n",
    "y3 = np.sum(sum(np.cov(lda_5.transform(user_item_sp_mat_1),lda_1.transform(user_item_sp_mat_1))))\n",
    "y5 = np.sum(sum(np.cov(lda_2.transform(user_item_sp_mat_1),lda_1.transform(user_item_sp_mat_1))))\n",
    "y6 = np.sum(sum(np.cov(lda_3.transform(user_item_sp_mat_1),lda_1.transform(user_item_sp_mat_1))))\n",
    "y7 = np.sum(sum(np.cov(lda_3.transform(user_item_sp_mat_1),lda_2.transform(user_item_sp_mat_1))))\n",
    "y8 = np.sum(sum(np.cov(lda_4.transform(user_item_sp_mat_1),lda_2.transform(user_item_sp_mat_1))))\n",
    "y = [y1,y2,y3,y5,y6,y7,y8]\n",
    "x = [1,2,3,4,5,6,7]\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "\n",
    "#Extra interesting ideas(using neutral network to do the non-linear dimensions reduction)\n",
    "##Input user features on artist into a neural network and get a output with n dimensions which is latent features represent the style\n",
    "##of the user. Do the same thing to artist and get a output represent the style of artist. The inner product of these latent features is the play times.\n",
    "##This is the process similar to LDA, but is non-linear. We hope this kind of non-linear model could explore more deep relationship between users and artists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
